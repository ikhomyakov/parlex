//! Grammar parser module.
//!
//! This module defines the core data structures and logic used for parsing
//! grammar definitions into an internal representation suitable for parser
//! generation. It provides the [`Symbol`] and [`Production`] types used to
//! represent grammar rules, along with a [`parser`] constructor function that
//! builds a parser capable of converting token streams into production rules.
//!
//! # Overview
//! The parser operates over a sequence of [`Token`]s (typically produced by the
//! crate’s [`lexer`](crate::lexer) module) and constructs an abstract grammar
//! representation. Each [`Production`] defines a nonterminal on the left-hand
//! side (LHS) and a sequence of terminals/nonterminals on the right-hand side (RHS).
//!
//! # Components
//! - [`Symbol`]: Represents either a terminal or nonterminal symbol by index.
//! - [`Production`]: Encapsulates a labeled grammar rule consisting of a LHS and RHS.
//! - [`parser()`]: Constructs the parser implementation that consumes tokens and
//!   produces a `Vec<Production>`.
//!
//! # Example
//! ```rust,ignore
//! use crate::parser::{parser, Production};
//! use crate::token::Token;
//!
//! let tokens: Vec<Token> = /* generated by lexer */;
//! let mut p = parser();
//! let productions: Vec<Production> = p.parse(&tokens).unwrap();
//! ```
//!
//! # See Also
//! - [`crate::lexer`]: For tokenization and lexical analysis.
//! - [`crate::parser_ctx`](crate::parser_ctx): For parser context management.
use super::lexer::Token;
use chumsky::prelude::*;

/// Represents a grammar symbol, which may be a terminal or nonterminal.
///
/// Used in grammar and production definitions to distinguish between
/// lexical tokens (terminals) and parser-level constructs (nonterminals).
#[derive(Debug, Clone, PartialEq)]
pub enum Symbol {
    /// A terminal symbol, represented by its index in the terminal symbol table.
    Term(usize),

    /// A nonterminal symbol, represented by its index in the nonterminal symbol table.
    NonTerm(usize),
}

/// Represents a grammar production rule.
///
/// Each production consists of a left-hand side (LHS) nonterminal and
/// a right-hand side (RHS) sequence of symbols. Productions may also have
/// an optional label for identification or debugging purposes.
#[derive(Debug, Clone, PartialEq)]
pub struct Production {
    /// Optional label index assigned to this production, if present.
    /// Labels are typically used for referencing named grammar rules.
    pub label: Option<usize>,

    /// Index of the left-hand side nonterminal symbol.
    pub lhs: usize,

    /// Sequence of right-hand side symbols that form this production.
    pub rhs: Vec<Symbol>,
}

/// Constructs and returns the grammar parser instance.
///
/// Builds a [`Parser`] implementation capable of consuming a token
/// stream (`&[Token]`) and producing a vector of grammar [`Production`]s.
///
/// # Lifetimes
/// - `'a`: The lifetime of the input token slice.
///
/// # Returns
/// A parser that processes a sequence of [`Token`]s into
/// a `Vec<Production>`, representing the parsed grammar rules.
pub fn parser<'a>() -> impl Parser<'a, &'a [Token], Vec<Production>> {
    let symbol = select! {
        Token::Term(t) => Symbol::Term(t),
        Token::NonTerm(n) => Symbol::NonTerm(n),
    }
    .labelled("symbol");

    let tlist = symbol.repeated().collect::<Vec<_>>();

    let left = select! {
        Token::NonTerm(n) => n,
    }
    .labelled("left");

    let prod_kw = select! { Token::Prod => () }.labelled("Prod");
    let lf = select! { Token::LineFeed => () }.labelled("LineFeed");

    let production_without_label = left
        .then_ignore(prod_kw.clone())
        .then(tlist.clone())
        .then_ignore(lf.clone())
        .map(|(lhs, rhs)| Production {
            label: None,
            lhs,
            rhs,
        })
        .map(Some);

    let production_with_label = select! { Token::ProdLabel(l) => l }
        .then(left)
        .then_ignore(prod_kw)
        .then(tlist)
        .then_ignore(lf.clone())
        .map(|((label, lhs), rhs)| Production {
            label: Some(label),
            lhs,
            rhs,
        })
        .map(Some);

    let empty_line = lf.map(|_| None::<Production>);

    let production = production_with_label
        .or(production_without_label)
        .or(empty_line);

    let productions = production
        .repeated()
        .collect::<Vec<_>>()
        .map(|items| items.into_iter().flatten().collect::<Vec<_>>());

    productions
}

/// Unit tests for the crate’s grammar parser component.
#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn single_production() {
        let tokens = vec![
            Token::ProdLabel(0),
            Token::NonTerm(1),
            Token::Prod,
            Token::Term(2),
            Token::NonTerm(3),
            Token::LineFeed,
        ];
        let prods = parser().parse(&tokens).unwrap();
        assert_eq!(prods.len(), 1);
        let p = &prods[0];
        assert_eq!(p.label, Some(0));
        assert_eq!(p.lhs, 1);
        assert_eq!(p.rhs, vec![Symbol::Term(2), Symbol::NonTerm(3)]);
    }

    #[test]
    fn empty_line_skipped() {
        let tokens = vec![Token::LineFeed];
        let prods = parser().parse(&tokens).unwrap();
        assert!(prods.is_empty());
    }

    #[test]
    fn multiple_productions() {
        let tokens = vec![
            Token::ProdLabel(10),
            Token::NonTerm(0),
            Token::Prod,
            Token::LineFeed, // empty rhs
            Token::ProdLabel(11),
            Token::NonTerm(2),
            Token::Prod,
            Token::Term(5),
            Token::LineFeed,
        ];
        let prods = parser().parse(&tokens).unwrap();
        assert_eq!(prods.len(), 2);
        assert_eq!(prods[0].label, Some(10));
        assert_eq!(prods[0].lhs, 0);
        assert!(prods[0].rhs.is_empty());
        assert_eq!(prods[1].label, Some(11));
        assert_eq!(prods[1].lhs, 2);
        assert_eq!(prods[1].rhs, vec![Symbol::Term(5)]);
    }
}
